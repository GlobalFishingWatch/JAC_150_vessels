---
title: "150_voi_test"
author: "Max Schofield"
date: "2022-10-21"
output:
  html_notebook:
  df_print: default
highlight: pygments
toc: yes
toc_float:
  toc_collapsed: true
toc_depth: 2

editor_options:
  chunk_output_type: inline
---

```{=html}
<style>
body {
text-align: justify}
</style>
```

# Setup

Knitr options 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load R packages 

```{r load packages}
foo <- function(x){
  for( i in x ){
    #  require returns TRUE invisibly if it was able to load package
    if( ! require( i , character.only = TRUE ) ){
      #  If package was not able to be loaded then re-install
      install.packages( i , dependencies = TRUE )
      #  Load package after installing
      require( i , character.only = TRUE )
    }
  }
}

#  Then try/install packages...
foo( c("tidyverse" , "bigrquery" ,"devtools", "DBI","glue", "lubridate", "here", "sf", "extrafont", "patchwork", "terra") )

# get fishwatch r independently 
if (!require("fishwatchr")) {devtools::install_github("GlobalFishingWatch/fishwatchr")}
library(fishwatchr)

```

Establish connection to BigQuery project

```{r con}
con <- DBI::dbConnect(drv = bigrquery::bigquery(), 
                      project = "world-fishing-827", 
                      use_legacy_sql = FALSE)
```

Set commonly used parameters for mapping

```{r}
# define bounding box/area of interest
# bbox <- data.frame(x_min = -8,
#                    x_max = 3,
#                    y_min = 0,
#                    y_max = 7)
# what projection should be used for mapping
best_proj <- fishwatchr::gfw_projections("Equal Earth")$proj_string
# best_proj <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
```


# Establish Vessel of Interest 

Calling the table directly as it is saved due to being a large query

First question is establish how many vessels have the 150 MMSI prefix in total. 

```{r, echo=FALSE}
q_voi_ais <- c("SELECT * FROM `world-fishing-827.scratch_max.raw_AIS_150_mmsi_prefix_2020_2022`")

all_150_ais <- fishwatchr::gfw_query(query = q_voi_ais,
                                 run_query = TRUE, 
                                 con = con)$data
n_distinct(all_150_ais$ssvid)

```

This is querying the raw AIS data and there is `r n_distinct(voi_ais$ssvid)` vessels in total. 

# Remove gear from 150 vessels  

Chunk trys to identify gear and has code to write out gear datasets (hashed as these are large dfs!)

```{r, echo=FALSE}
# outside china gets all 150 vessels AIS outside of China 
outside_chn <- readr::read_file(file = here::here("queries", ".", "outside_CHN.sql"))
outside_chn_ais<- fishwatchr::gfw_query(query = outside_chn,
                                 run_query = TRUE,
                                 con = con)$data

# write.csv(outside_chn_ais, '../data/step1_outside_CHN.csv', row.names = F)

n_distinct(outside_chn_ais$ssvid)

# restrict down to genuine VOI
outside_AIS <- filter(all_150_ais, ssvid %in% c(outside_chn_ais$ssvid))

# get rid of percentage - indicator of gear markers 
per <- filter(outside_AIS, stringr::str_detect(shipname, '\\%'))

# get rid of ending in v - another indicator of gear markers
per_v <- filter(outside_AIS, stringr::str_detect(shipname, 'v$|V$'))

# get rid of ending in NET another indicator of gear markers
per_v_net <- filter(outside_AIS, stringr::str_detect(shipname, 'NET'))

# get rid of - in the name as another indicator of gear markers
per_v_net_dash <- filter(outside_AIS, stringr::str_detect(shipname, '-'))

# remove vessels
no_per_v_net_dash <- outside_AIS %>% filter(!ssvid %in% unique(c(
    per$ssvid, 
    per_v$ssvid,
    per_v_net$ssvid, 
    per_v_net_dash$ssvid)))

# write out data to visaulise
# write.csv(no_per_v_net_dash, '../data/non_gear_outside_CHN.csv', row.names = F)

# write out the discarded datasets to see if any aligns with areas of interest 
# write.csv(per, '../data/150voi_percentage_in_name.csv', row.names = F)
# write.csv(per_v, '../data/150voi_voltage_in_name.csv', row.names = F)
# write.csv(per_v_net, '../data/150voi_net_in_name.csv', row.names = F)
# write.csv(per_v_net_dash, '../data/150voi_dash_in_name.csv', row.names = F)

n_distinct(outside_AIS$ssvid)
n_distinct(no_per_v_net_dash$ssvid)

data <- no_per_v_net_dash[!is.na(no_per_v_net_dash$lat) & !is.na(no_per_v_net_dash$lon) ,]
n_distinct(data$ssvid)

# still missing where a big chunk data drops out 
# check the opposite of the gear query 

likely_gear <- outside_AIS %>% filter(ssvid %in% unique(c(
    per$ssvid, 
    per_v$ssvid,
    per_v_net$ssvid, 
    per_v_net_dash$ssvid)))
# write.csv(likely_gear, '../data/likely_gear.csv', row.names = F)
```

# Look at activity outside of China

Lots of the activity and ssvids are only active in the Chinese EEZ, this activity is 
unrelated to the activity of interest in existing JAC intreps and should be removed. 

The code also looks at setting a limit on minimum number of points outside of China 
to try and remove vessels active in the Chinese EEZ with a number of positional 
anomalies outside of this location. 

```{r, echo=FALSE}

# still lots of CHN transmissions. Drop them with a lat/lon subset to make sure we don't still have
# exclusively chinese vessels 
# add index to data 
voi <- data %>% mutate(id = seq(1,nrow(data),1))
chn <- voi %>% filter(between(lon, 107, 124) & between(lat, 18, 41))
n_distinct(chn$ssvid)
n_distinct(voi$ssvid)

# remove data points in China. 
look <- voi %>% filter(!id %in% chn$id)
n_distinct(look$ssvid)
# write.csv(look, '../data/outside_chn_v2.csv', row.names = F)

# run more then 10 transmission query to  remove vessels with bitflips out of CHN 
more_then10 <- look %>% group_by(ssvid) %>% summarise(n=n()) %>% filter(n>10)
outside_chn_more_then10 <- look %>% filter(ssvid %in% (more_then10$ssvid))
n_distinct(outside_chn_more_then10$ssvid)

# run more then 5 transmission query to  remove vessels with bitflips out of CHN 
more_then5 <- look %>% group_by(ssvid) %>% summarise(n=n()) %>% filter(n>5)
outside_chn_more_then5 <- look %>% filter(ssvid %in% (more_then5$ssvid))
n_distinct(outside_chn_more_then5$ssvid)


# writing out data. hashed as dfs are large for
######
# outside_chn_more_then10 %>% write.csv(here::here("data", ".", paste0("active_outside_chn_10_",str_replace_all(Sys.Date(), '-','_'),".csv")))
# outside_chn_more_then5 %>% write.csv(here::here("data", ".", paste0("active_outside_chn_5_",str_replace_all(Sys.Date(), '-','_'),".csv")))
# look %>% filter(!ssvid %in% (outside_chn_more_then10$ssvid))%>% write.csv(here::here("data", ".", paste0("dropped_outside_chn_10_",str_replace_all(Sys.Date(), '-','_'),".csv")))
# look %>% filter(!ssvid %in% (outside_chn_more_then5$ssvid)) %>% write.csv(here::here("data", ".", paste0("dropped_outside_chn_5_",str_replace_all(Sys.Date(), '-','_'),".csv")))
# 

drp_5 <- look %>% filter(!ssvid %in% (outside_chn_more_then5$ssvid))
#View(drp_5 %>% group_by(ssvid) %>% summarise(n=n()))
# pattern with 15040 being in our fleet of interest. 

# # look at data dropped by the more then 10 criteria 
# removed <- data %>% filter(!ssvid %in% (more_then10$ssvid))
# write.csv(removed, '../data/removed.csv', row.names = F)
# check_ids <-  removed %>% group_by(ssvid) %>% summarise(trans=n()) %>% filter(trans>10)
# 
# check <- filter(removed,  ssvid %in% check_ids$ssvid)
# write.csv(check, '../data/check.csv', row.names = F)
# # working as expected
# write it out to visaulise
# write.csv(outside_chn_more_then10, '../data/active_outside_chn.csv', row.names = F)

# create more then 10 threshold
more_then10_int <- look %>% group_by(ssvid) %>% summarise(n=n()) %>% filter(n>10 | str_detect(ssvid, "^15040"))

# create new working df with vessels with >10 transmissions not thought to be gear 
working_df <- filter(data, ssvid %in% more_then10_int$ssvid)

# look to see is 15040 is the vessel of interest 
table(filter(data, str_detect(ssvid, "^15040"))$shipname)
table(working_df$shipname)

# collate some information on vessels of interest dataset
match_ves <- working_df %>% 
    group_by(ssvid) %>% 
      summarise(positions = n(), 
                names = paste(unique(shipname), collapse="; "), 
                first_timestamp = min(timestamp), 
                last_timestamp = max(timestamp), 
                timespan = difftime(last_timestamp, first_timestamp, units="days")) %>%
        arrange(desc(positions))
              
#View(match_ves)

# write out df 
#match_ves %>% write.csv(here::here("data", ".", paste0("150_voi_usage_spire_",str_replace_all(Sys.Date(), '-','_'),".csv")))

# filter the whole dataset to only retain the active outside of china vessels (with their china transmissions)
focal <- all_150_ais %>% filter(ssvid %in% unique(outside_chn_more_then10$ssvid)) 
focal <- focal[!is.na(focal$lat) & !is.na(focal$lon) ,]
# focal <- voi_ais %>% filter(ssvid %in% unique(active_outside_chn$ssvid)) 
# write.csv(focal, '../data/all_ais_150_active.csv', row.names = F)

# voi %>% group_by(ssvid) %>% arrange(ssvid, timestamp) %>% mutate(time = difftime(timestamp, lag(timestamp)))

```

Of the `r n_distinct(voi_ais$ssvid)` total MMSIs associated with the 150 prefix,  `r n_distinct(outside_chn_vessels$ssvid)` transmitted outside the Chinese EEZ. 

Of the MMSIs operating outside China many have names which indicated they are associated 
with likely fishing gear. MMSIs associated with likely gear was removed from our vessel
of interest list based on removing MMSIs either transmitting a %, a Voltage indicator (V), 
the word 'NET' in the shipname, which are indicators of fishing gear. 

This filtering removed `r n_distinct(outside_AIS$ssvid) - n_distinct(no_per_v_net_dash$ssvid)`
MMSIs from our fleet of interest. Resulting in `r n_distinct(no_per_v_net_dash$ssvid)` remaining 
in our vessels of interest. 

Further filtering was conducted on vessels with less than 10 AIS transmissions between 2021 and 2022 which removed `r n_distinct(outside_AIS$ssvid) - n_distinct(more_then10$ssvid)` vessel from the analysis fleet leaving `n_distinct(more_then10$ssvid)` vessels. 

# Patterns in remaining vessel names  

```{r, echo=FALSE}
# investigate patterns in shipnames 
#ssvids <- working_df %>% filter(str_detect(shipname, '20'))
#View(working_df %>% filter(ssvid %in% unique(ssvids$ssvid)) %>% group_by(ssvid) %>% summarise(names=paste(unique(shipname), collapse=" ")))

# test voi field 
paste0("('",paste(unique(working_df$ssvid), collapse="','"), "')")

# query to investigate identity data from vi_ssvid table 
voi_identity_q <- c("
  SELECT 
    ssvid, 
    ais_identity.n_shipname_mostcommon.value AS best_shipname_AIS,
    ais_identity.n_callsign_mostcommon.value AS best_callsign_AIS,
    ais_identity.n_imo_mostcommon.value AS best_imo_AIS,
    registry_info.best_known_shipname, 
    registry_info.best_known_callsign,
    registry_info.best_known_imo,
    registry_info.best_known_flag,
    registry_info.best_known_vessel_class,
    best.best_flag, 
    best.best_vessel_class, 
    on_fishing_list_known, 
    on_fishing_list_nn
  FROM `gfw_research.vi_ssvid_v20230101`
  WHERE   
  ssvid IN {voi}
  ")

# run query for specified voi - in this case the whole working df 
voi_identity <- fishwatchr::gfw_query(query = glue::glue(voi_identity_q,
                                               voi = paste0("('",paste(unique(working_df$ssvid), collapse="','"), "')")),
                                 run_query = TRUE,
                                 con = con)$data

View(voi_identity)

# explore individual mmsis
table(filter(working_df, ssvid == '412331282')$shipname)
table(filter(working_df, str_detect(shipname, 'SHUN HANG 6'))$ssvid)
table(filter(working_df, str_detect(shipname, 'SHUN'))$shipname)

# look at the frequency of different shipname usage 
voi_gfw_names_q <- c("
  SELECT 
    ssvid, 
    shipname.count AS frequency, 
    shipname.value AS shipname
  FROM `gfw_research.vi_ssvid_v20230101`
  LEFT JOIN UNNEST(ais_identity.shipname) AS shipname
  WHERE   
  ssvid IN {voi}
  ")

voi_names <- fishwatchr::gfw_query(query = glue::glue(voi_gfw_names_q,
                                               voi = paste0("('",paste(unique(working_df$ssvid), collapse="','"), "')")),
                                 run_query = TRUE,
                                 con = con)$data
getwd()
#write.csv(voi_identity, "../data/150_voi_names_frequency.csv")
  
```


```{r, echo=FALSE}
# look at the prevelance of using multiple names 
names_df <- focal %>% group_by(ssvid) %>% summarise(names = n_distinct(shipname), 
                                        callsigns = n_distinct(shipname)) #%>% group_by(names) %>% 
# plot this out 
ggplot(names_df) +
  geom_histogram(aes(x=names)) +
  labs(x='Number of Names', y='Number of Vessels')+
  theme_gfw()+
  # theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), 
        axis.text=element_text(size=11), axis.title=element_text(size=12,face="bold"), 
        legend.title=element_text(size=12), legend.text=element_text(size=11)) 

#table(focal$shipname)

```

 <span style="color:red">Note this text summary is deprecated with more recent analysis done by El which will be the basis of the research report</span>

The vessel of interest have five distinct vessel name groupings within them
1. names starting with FU of which there are `r n_distinct(filter(voi_ais, stringr::str_starts(shipname, 'FU'))$shipname)` distinct names with FU YUAN YU ... the most common pattern
2. names starting with HAI of which there are `r n_distinct(filter(voi_ais, stringr::str_starts(shipname, 'HAI'))$shipname)` distinct names with HAI YANG ... the most common pattern
3. names starting with LU RONG which there are `r n_distinct(filter(voi_ais, stringr::str_starts(shipname, 'LU'))$shipname)` distinct names with LURONG YUAN YU ... the most common pattern
4. names starting with SHUN HANG which there are `r n_distinct(filter(voi_ais, stringr::str_starts(shipname, 'SHUN'))$shipname)` distinct names following this pattern. This aligns with SHUN HANG which are an AIS unit manufacturer and may relate to units being reset.

One further vessel had the name LU QING YUAN YU 290. Only one MMSI transmitted this vessel name. 

Clear vessel names with some iterations in the dataset
- FU YUAN YU 715
- FU YUAN YU 717
- FU YUAN YU 9993
- FU YUAN YU 9994
- HAI HANG 1 
- HAI HANG 2
- HAI HANG 3
- HAI HANG 5
- HAI HANG 6 
- LU QING YUAN YU 290
- LU RONG YUAN YU 195 
- LU RONG YUAN YU 581 
- LU RONG YUAN YU 715 
- LU RONG YUAN YU 197 
- LU RONG YUAN YU 20 
- LU RONG YUAN YU 277 
- LU RONG YUAN YU 278 
- LU RONG YUAN YU 717 
- LU RONG YUAN YU 715 
- SHUN HANG 1 
- SHUN HANG 2
- SHUN HANG 3
- SHUN HANG 5
- SHUN HANG 6

# Established voi list 
```{r, echo=FALSE}
# Read in agreed 225 voi with TMT 

q_voi_est <- c("SELECT * FROM `world-fishing-827.scratch_max.150_voi_ssvid`")

voi_est <- fishwatchr::gfw_query(query = q_voi_est,
                                 run_query = TRUE, 
                                 con = con)$data
```

## Location

# Location in space and time

Look at the consistency of location and fleet size through space and time.

```{r, echo=FALSE}
working_df$year  <- year(working_df$timestamp) 
working_df$month  <- month(working_df$timestamp) 
#working_df %>% write.csv(here::here("data", ".", paste0("150_voi_working_df_",str_replace_all(Sys.Date(), '-','_'),".csv")))

# write out annual dfs to visaulise location and timing in QGIS
# filter(working_df, year == '2020') %>% write.csv(here::here("data", ".", paste0("150_voi_working_df_2020_",str_replace_all(Sys.Date(), '-','_'),".csv")))
# filter(working_df, year == '2021') %>% write.csv(here::here("data", ".", paste0("150_voi_working_df_2021_",str_replace_all(Sys.Date(), '-','_'),".csv")))
# filter(working_df, year == '2022') %>% write.csv(here::here("data", ".", paste0("150_voi_working_df_2022_",str_replace_all(Sys.Date(), '-','_'),".csv")))
```

Map

```{r, echo=FALSE}

# lets aggregate the data to lat/lon bins to use fishwatchr example mapping code 
working_df$lat_bin <- round(working_df$lat,1)
working_df$lon_bin <- round(working_df$lon,1)

presence <- working_df %>%
  group_by(lat_bin, lon_bin) %>%
    summarise(
      positions = n(), 
    )

  presence %>%
  recenter_raster(raster_df = .,
                  res = 1,
                  x_lab = 'lon_bin',
                  y_lab = 'lat_bin',
                  fill_lab = 'positions',
                  center = -80) %>%
  ggplot() +
  geom_raster(aes(x = lon_bin,
                  y = lat_bin,
                  fill = positions)) +
  geom_gfw_land(theme = 'light', center = -80) +
  geom_gfw_eez(theme = 'light', center = -80, alpha = 0.05) +
  scale_fill_gradientn(colors = gfw_palette('map_effort_dark'),
                       limits = c(0,10000),
                       oob = scales::squish,
                       na.value = NA) +
  labs(fill = 'AIS Positions') +
  theme_gfw_map(theme = 'light')

ggsave(here::here("outputs", "figures", "voi_ais_map.png"))

```

# Ports 

# Chinese Ports 
```{r, echo=FALSE}
chn_ports <- readr::read_file(file = here::here("queries", ".", "150_voi_chn_ports.sql"))
outside_chn_ais<- fishwatchr::gfw_query(query = chn_ports,
                                 run_query = TRUE,
                                 con = con)$data
```

# AIS Name changes

We want to evaluate when and where vessel of interest are changing there names. 

```{r, echo=F}
ais_change_location_q <- readr::read_file(file = here::here("queries", ".", "ais_identity_changes_v1.sql"))
name_change <- fishwatchr::gfw_query(query = ais_change_location_q,
                                 run_query = TRUE,
                                 con = con)$data

# identify LU RONG YUAN YU 715 change points 
# this name used on 13 MMSIs 
lryy715 <- bind_rows(
  # static 
  name_change %>% filter(stringr::str_detect(static_name, '715$') |
                       static_name  == 'LURONGYUANYU715' |
                       static_name  == 'LURONGYUANYU 715'),
  # prev 
  name_change %>% filter(stringr::str_detect(next_name, '715$') |
                       next_name == 'LURONGYUANYU715' |
                       next_name == 'LURONGYUANYU 715')
  )

View(lryy715)
# three names id through changes 

# what about non name changing vessels 


```


# AIS message types

```{r, echo=FALSE}
# Need to add class B element 

```



